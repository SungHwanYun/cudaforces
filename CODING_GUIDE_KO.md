# ğŸ“˜ CUDA Online Judge ì½”ë”© ê°€ì´ë“œ

**CUDA í”„ë¡œê·¸ë˜ë° í•™ìŠµì„ ìœ„í•œ ì˜¨ë¼ì¸ ì €ì§€ í”Œë«í¼ ì‚¬ìš© ê°€ì´ë“œ**

---

## ğŸ“š ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#1-ì‹œìŠ¤í…œ-ê°œìš”)
2. [CPU Transpilerë€?](#2-cpu-transpilerë€)
3. [ì½”ë“œ ê²€ì¦ (Validation)](#3-ì½”ë“œ-ê²€ì¦-validation)
4. [ì§€ì› ê¸°ëŠ¥ ëª©ë¡](#4-ì§€ì›-ê¸°ëŠ¥-ëª©ë¡)
5. [ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬](#5-ì‚¬ìš©-ê°€ëŠ¥í•œ-ë¼ì´ë¸ŒëŸ¬ë¦¬)
6. [ì‚¬ìš© ê¸ˆì§€ í•­ëª©](#6-ì‚¬ìš©-ê¸ˆì§€-í•­ëª©)
7. [ì—ëŸ¬ ì½”ë“œ ëª©ë¡](#7-ì—ëŸ¬-ì½”ë“œ-ëª©ë¡)
8. [ì½”ë”© ê°€ì´ë“œë¼ì¸](#8-ì½”ë”©-ê°€ì´ë“œë¼ì¸)
9. [ì£¼ì˜ì‚¬í•­ ë° ì œí•œì‚¬í•­](#9-ì£¼ì˜ì‚¬í•­-ë°-ì œí•œì‚¬í•­)
10. [ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)](#10-ìì£¼-ë¬»ëŠ”-ì§ˆë¬¸-faq)

---

## 1. ì‹œìŠ¤í…œ ê°œìš”

### 1.1 CUDA Online Judgeë€?

CUDA Online JudgeëŠ” GPU í”„ë¡œê·¸ë˜ë°ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ êµìœ¡ìš© ì˜¨ë¼ì¸ ì±„ì  ì‹œìŠ¤í…œì…ë‹ˆë‹¤. 
ì‹¤ì œ GPUê°€ ì—†ì–´ë„ CUDA ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1.2 ì±„ì  ë°©ì‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CUDA ì½”ë“œ  â”‚ ---> â”‚ Transpiler  â”‚ ---> â”‚  C++ ì½”ë“œ   â”‚ ---> â”‚  CPU ì‹¤í–‰   â”‚
â”‚  (ì œì¶œ)     â”‚ ë³€í™˜  â”‚             â”‚ ìƒì„±  â”‚             â”‚ ì»´íŒŒì¼ â”‚  & ì±„ì     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- ì œì¶œëœ CUDA ì½”ë“œëŠ” **CPUì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ C++ ì½”ë“œë¡œ ë³€í™˜**ë©ë‹ˆë‹¤
- OpenMPë¥¼ ì‚¬ìš©í•˜ì—¬ GPUì˜ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤
- ì¶œë ¥ ê²°ê³¼ì˜ **ì •í™•ì„±**ë§Œ í‰ê°€í•©ë‹ˆë‹¤

### 1.3 ì±„ì  ê²°ê³¼ ì¢…ë¥˜

| ê²°ê³¼ | ì„¤ëª… |
|------|------|
| âœ… **Accepted (AC)** | ì •ë‹µ - ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í†µê³¼ |
| âŒ **Wrong Answer (WA)** | ì˜¤ë‹µ - ì¶œë ¥ì´ ì •ë‹µê³¼ ë‹¤ë¦„ |
| âš ï¸ **Compile Error (CE)** | ì»´íŒŒì¼ ì—ëŸ¬ - ë¬¸ë²• ì˜¤ë¥˜ |
| â±ï¸ **Time Limit Exceeded (TLE)** | ì‹œê°„ ì´ˆê³¼ |
| ğŸ’¾ **Memory Limit Exceeded (MLE)** | ë©”ëª¨ë¦¬ ì´ˆê³¼ |
| ğŸš« **Runtime Error (RE)** | ëŸ°íƒ€ì„ ì—ëŸ¬ - ì„¸ê·¸í´íŠ¸ ë“± |
| ğŸ”’ **Validation Error (VE)** | ê²€ì¦ ì‹¤íŒ¨ - CUDA ê·œì¹™ ìœ„ë°˜ |

---

## 2. CPU Transpilerë€?

### 2.1 ê°œë…

**CPU Transpiler**ëŠ” CUDA ì½”ë“œë¥¼ GPU ì—†ì´ CPUì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```cuda
// ì›ë³¸ CUDA ì½”ë“œ
__global__ void add(int* a, int* b, int* c) {
    int i = threadIdx.x;
    c[i] = a[i] + b[i];
}

// ì»¤ë„ í˜¸ì¶œ
add<<<1, 5>>>(d_a, d_b, d_c);
```

ìœ„ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë³€í™˜ë©ë‹ˆë‹¤:

```cpp
// ë³€í™˜ëœ C++ ì½”ë“œ (OpenMP ë³‘ë ¬í™”)
void add_impl(int threadIdx_x, ..., int* a, int* b, int* c) {
    struct { int x; } threadIdx = {threadIdx_x};
    int i = threadIdx.x;
    c[i] = a[i] + b[i];
}

// ì»¤ë„ ëŸ°ì¹˜ â†’ OpenMP ë£¨í”„
#pragma omp parallel for
for (int tx = 0; tx < 5; tx++) {
    add_impl(tx, ..., d_a, d_b, d_c);
}
```

### 2.2 ë³€í™˜ ë°©ì‹

| CUDA ìš”ì†Œ | CPU ë³€í™˜ ë°©ì‹ |
|-----------|--------------|
| `__global__` í•¨ìˆ˜ | ì¼ë°˜ C++ í•¨ìˆ˜ |
| `<<<blocks, threads>>>` | OpenMP ì¤‘ì²© ë£¨í”„ |
| `threadIdx.x/y/z` | í•¨ìˆ˜ íŒŒë¼ë¯¸í„° |
| `blockIdx.x/y/z` | í•¨ìˆ˜ íŒŒë¼ë¯¸í„° |
| `blockDim.x/y/z` | í•¨ìˆ˜ íŒŒë¼ë¯¸í„° |
| `cudaMalloc` | `malloc` |
| `cudaMemcpy` | `memcpy` |
| `cudaFree` | `free` |
| `__shared__` | ë¸”ë¡ë³„ ë…ë¦½ ë°°ì—´ |
| `atomicAdd` | `__atomic_fetch_add` |
| `__syncthreads()` | `#pragma omp barrier` |

### 2.3 âš ï¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë¶ˆê°€

> **ì¤‘ìš”**: ì´ ì‹œìŠ¤í…œì€ **ì •í™•ì„± ê²€ì¦**ë§Œì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.

**ì„±ëŠ¥ ì¸¡ì •ì´ ì˜ë¯¸ì—†ëŠ” ì´ìœ :**

1. **ì‹¤ì œ GPUì™€ ë‹¤ë¥¸ ì‹¤í–‰ í™˜ê²½**
   - GPUëŠ” ìˆ˜ì²œ ê°œì˜ ìŠ¤ë ˆë“œë¥¼ ë™ì‹œì— ì‹¤í–‰
   - CPU ì—ë®¬ë ˆì´ì…˜ì€ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
   
2. **ë©”ëª¨ë¦¬ êµ¬ì¡° ì°¨ì´**
   - GPUì˜ ê³ ì† ë©”ëª¨ë¦¬ ê³„ì¸µ (L1/L2/Shared/Global)ì´ ì—†ìŒ
   - ëª¨ë“  ë©”ëª¨ë¦¬ê°€ ì‹œìŠ¤í…œ RAMìœ¼ë¡œ ë§¤í•‘

3. **ì‹œê°„ ë³µì¡ë„ ì°¨ì´**
   - GPUì—ì„œ O(1)ì¸ ë³‘ë ¬ ì—°ì‚°ì´ CPUì—ì„œ O(n)ì´ ë  ìˆ˜ ìˆìŒ

```cuda
// ì´ ì½”ë“œì˜ GPU ì„±ëŠ¥ â‰  CPU íŠ¸ëœìŠ¤íŒŒì¼ ì„±ëŠ¥
__global__ void matMul(float* A, float* B, float* C, int N) {
    // GPU: ëª¨ë“  ìŠ¤ë ˆë“œ ë™ì‹œ ì‹¤í–‰
    // CPU: ìŠ¤ë ˆë“œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
}
```

**ê¶Œì¥ ì‚¬í•­:**
- ì•Œê³ ë¦¬ì¦˜ì˜ **ì •í™•ì„±**ë§Œ ê²€ì¦í•˜ì„¸ìš”
- ì‹¤ì œ ì„±ëŠ¥ ìµœì í™”ëŠ” GPUê°€ ìˆëŠ” í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”
- `cudaEvent`ë¡œ ì¸¡ì •í•œ ì‹œê°„ì€ ì˜ë¯¸ê°€ ì—†ìŠµë‹ˆë‹¤ (í•­ìƒ 0 ë°˜í™˜)

---

## 3. ì½”ë“œ ê²€ì¦ (Validation)

ì œì¶œëœ ì½”ë“œëŠ” ë‹¤ìŒ ê²€ì¦ì„ í†µê³¼í•´ì•¼ í•©ë‹ˆë‹¤:

### 3.1 í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

| ê²€ì¦ í•­ëª© | ì„¤ëª… | ì—ëŸ¬ ì½”ë“œ |
|-----------|------|-----------|
| âœ… **ì»¤ë„ ì¡´ì¬** | ìµœì†Œ 1ê°œì˜ `__global__` í•¨ìˆ˜ í•„ìš” | E3001 |
| âœ… **ì˜ë¯¸ìˆëŠ” ì—°ì‚°** | ì»¤ë„ì´ ì‹¤ì œ ê³„ì‚°ì„ ìˆ˜í–‰í•´ì•¼ í•¨ | E3002 |
| âœ… **ë³‘ë ¬ì²˜ë¦¬ ì‚¬ìš©** | `threadIdx`, `blockIdx` ë“± ì‚¬ìš© í•„ìš” | E3003 |
| âœ… **GPU ë©”ëª¨ë¦¬ ì‚¬ìš©** | `cudaMalloc`, `cudaMemcpy` ì‚¬ìš© í•„ìš” | E3004 |
| âœ… **ì»¤ë„ í˜¸ì¶œ** | ì •ì˜ëœ ì»¤ë„ì„ `<<<>>>` êµ¬ë¬¸ìœ¼ë¡œ í˜¸ì¶œ | E3001 |
| âŒ **ê¸ˆì§€ í•¨ìˆ˜ ë¯¸ì‚¬ìš©** | `qsort`, STL í•¨ìˆ˜ ë“± ì‚¬ìš© ë¶ˆê°€ | E3005 |
| âŒ **ê¸ˆì§€ íƒ€ì… ë¯¸ì‚¬ìš©** | `std::vector`, `std::string` ë“± ì‚¬ìš© ë¶ˆê°€ | E3006 |

### 3.2 ì˜ë¯¸ìˆëŠ” ì»¤ë„ ì¡°ê±´

ë‹¤ìŒ ì¤‘ **í•˜ë‚˜ ì´ìƒ**ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:

```cuda
// âœ… ì¡°ê±´ 1: ê³„ì‚° ìˆ˜í–‰
__global__ void kernel1(int* a, int* b, int* c) {
    c[i] = a[i] + b[i];  // ì‚°ìˆ  ì—°ì‚°
}

// âœ… ì¡°ê±´ 2: íŒŒë¼ë¯¸í„° ì‚¬ìš©
__global__ void kernel2(int* data, int n) {
    data[threadIdx.x] = n;  // íŒŒë¼ë¯¸í„° ì ‘ê·¼
}

// âœ… ì¡°ê±´ 3: ë°°ì—´ ì ‘ê·¼
__global__ void kernel3(int* arr) {
    arr[threadIdx.x] = 1;  // ë©”ëª¨ë¦¬ ì ‘ê·¼
}

// âœ… ì¡°ê±´ 4: ì¶œë ¥ ìˆ˜í–‰
__global__ void kernel4() {
    printf("Hello from GPU!\n");  // ì¶œë ¥
}
```

### 3.3 ë³‘ë ¬ì²˜ë¦¬ ê²€ì¦

ì»¤ë„ ë‚´ì—ì„œ ë‹¤ìŒ ë¹ŒíŠ¸ì¸ ë³€ìˆ˜ë¥¼ **í•˜ë‚˜ ì´ìƒ** ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤:

- `threadIdx.x`, `threadIdx.y`, `threadIdx.z`
- `blockIdx.x`, `blockIdx.y`, `blockIdx.z`
- `blockDim.x`, `blockDim.y`, `blockDim.z`
- `gridDim.x`, `gridDim.y`, `gridDim.z`

```cuda
// âŒ ê²€ì¦ ì‹¤íŒ¨: ë³‘ë ¬ì²˜ë¦¬ ë¯¸ì‚¬ìš©
__global__ void bad_kernel(int* arr) {
    arr[0] = 1;  // ëª¨ë“  ìŠ¤ë ˆë“œê°€ ê°™ì€ ì‘ì—…
}

// âœ… ê²€ì¦ í†µê³¼: ë³‘ë ¬ì²˜ë¦¬ ì‚¬ìš©
__global__ void good_kernel(int* arr) {
    int i = threadIdx.x;  // ìŠ¤ë ˆë“œë³„ ë‹¤ë¥¸ ì¸ë±ìŠ¤
    arr[i] = i;
}
```

### 3.4 GPU ë©”ëª¨ë¦¬ ê²€ì¦

main í•¨ìˆ˜ì—ì„œ ë‹¤ìŒ í•¨ìˆ˜ë¥¼ **í•˜ë‚˜ ì´ìƒ** ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤:

- `cudaMalloc`
- `cudaMemcpy` (ë˜ëŠ” `cudaMemcpyAsync`)
- `cudaMemset` (ë˜ëŠ” `cudaMemsetAsync`)

```cuda
// âŒ ê²€ì¦ ì‹¤íŒ¨: GPU ë©”ëª¨ë¦¬ ë¯¸ì‚¬ìš©
int main() {
    int arr[10];
    kernel<<<1, 10>>>(arr);  // ì§ì ‘ í˜¸ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ ì „ë‹¬
}

// âœ… ê²€ì¦ í†µê³¼: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©
int main() {
    int *d_arr;
    cudaMalloc(&d_arr, 10 * sizeof(int));  // GPU ë©”ëª¨ë¦¬ í• ë‹¹
    cudaMemcpy(d_arr, arr, 10 * sizeof(int), cudaMemcpyHostToDevice);
    kernel<<<1, 10>>>(d_arr);
    cudaFree(d_arr);
}
```

---

## 4. ì§€ì› ê¸°ëŠ¥ ëª©ë¡

### 4.1 í•¨ìˆ˜ í‚¤ì›Œë“œ

| í‚¤ì›Œë“œ | ì„¤ëª… | ì§€ì› |
|--------|------|------|
| `__global__` | GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” ì»¤ë„ í•¨ìˆ˜ | âœ… |
| `__device__` | GPUì—ì„œë§Œ í˜¸ì¶œ ê°€ëŠ¥í•œ í•¨ìˆ˜ | âœ… |
| `__host__` | CPUì—ì„œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜ | âœ… |
| `__host__ __device__` | CPU/GPU ëª¨ë‘ í˜¸ì¶œ ê°€ëŠ¥ | âœ… |

### 4.2 ë©”ëª¨ë¦¬ í‚¤ì›Œë“œ

| í‚¤ì›Œë“œ | ì„¤ëª… | ì§€ì› |
|--------|------|------|
| `__shared__` | ë¸”ë¡ ë‚´ ê³µìœ  ë©”ëª¨ë¦¬ (ì •ì ) | âœ… |
| `extern __shared__` | ë™ì  ê³µìœ  ë©”ëª¨ë¦¬ | âœ… |
| `__device__` | ë””ë°”ì´ìŠ¤ ì „ì—­ ë³€ìˆ˜ | âœ… |
| `__constant__` | ìƒìˆ˜ ë©”ëª¨ë¦¬ | âœ… |

### 4.3 ë¹ŒíŠ¸ì¸ ë³€ìˆ˜

| ë³€ìˆ˜ | ì„¤ëª… | ì§€ì› |
|------|------|------|
| `threadIdx.x/y/z` | ë¸”ë¡ ë‚´ ìŠ¤ë ˆë“œ ì¸ë±ìŠ¤ | âœ… |
| `blockIdx.x/y/z` | ê·¸ë¦¬ë“œ ë‚´ ë¸”ë¡ ì¸ë±ìŠ¤ | âœ… |
| `blockDim.x/y/z` | ë¸”ë¡ë‹¹ ìŠ¤ë ˆë“œ ìˆ˜ | âœ… |
| `gridDim.x/y/z` | ê·¸ë¦¬ë“œ ë‚´ ë¸”ë¡ ìˆ˜ | âœ… |
| `warpSize` | ì›Œí”„ í¬ê¸° (32) | âœ… |

### 4.4 ë©”ëª¨ë¦¬ ê´€ë¦¬ í•¨ìˆ˜

| í•¨ìˆ˜ | ì„¤ëª… | ì§€ì› |
|------|------|------|
| `cudaMalloc` | GPU ë©”ëª¨ë¦¬ í• ë‹¹ | âœ… |
| `cudaFree` | GPU ë©”ëª¨ë¦¬ í•´ì œ | âœ… |
| `cudaMemcpy` | ë©”ëª¨ë¦¬ ë³µì‚¬ | âœ… |
| `cudaMemcpyAsync` | ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ë³µì‚¬ | âœ… |
| `cudaMemset` | ë©”ëª¨ë¦¬ ì´ˆê¸°í™” | âœ… |
| `cudaMemsetAsync` | ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì´ˆê¸°í™” | âœ… |
| `cudaMemcpyToSymbol` | ì‹¬ë³¼ë¡œ ë³µì‚¬ | âœ… |
| `cudaMemcpyFromSymbol` | ì‹¬ë³¼ì—ì„œ ë³µì‚¬ | âœ… |
| `cudaMemGetInfo` | ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ | âœ… |

### 4.5 Atomic ì—°ì‚°

| í•¨ìˆ˜ | ì„¤ëª… | ì§€ì› |
|------|------|------|
| `atomicAdd` | ì›ìì  ë§ì…ˆ | âœ… |
| `atomicSub` | ì›ìì  ëº„ì…ˆ | âœ… |
| `atomicExch` | ì›ìì  êµí™˜ | âœ… |
| `atomicMin` | ì›ìì  ìµœì†Ÿê°’ | âœ… |
| `atomicMax` | ì›ìì  ìµœëŒ“ê°’ | âœ… |
| `atomicInc` | ì›ìì  ì¦ê°€ (ëª¨ë“ˆëŸ¬) | âœ… |
| `atomicDec` | ì›ìì  ê°ì†Œ (ëª¨ë“ˆëŸ¬) | âœ… |
| `atomicCAS` | Compare-And-Swap | âœ… |
| `atomicAnd` | ì›ìì  AND | âœ… |
| `atomicOr` | ì›ìì  OR | âœ… |
| `atomicXor` | ì›ìì  XOR | âœ… |

### 4.6 ë™ê¸°í™” í•¨ìˆ˜

| í•¨ìˆ˜ | ì„¤ëª… | ì§€ì› |
|------|------|------|
| `__syncthreads()` | ë¸”ë¡ ë‚´ ìŠ¤ë ˆë“œ ë™ê¸°í™” | âœ… |
| `__syncwarp()` | ì›Œí”„ ë‚´ ë™ê¸°í™” | âœ… |
| `cudaDeviceSynchronize()` | ë””ë°”ì´ìŠ¤ ë™ê¸°í™” | âœ… |
| `cudaStreamSynchronize()` | ìŠ¤íŠ¸ë¦¼ ë™ê¸°í™” | âœ… |

### 4.7 Warp ì—°ì‚°

| í•¨ìˆ˜ | ì„¤ëª… | ì§€ì› |
|------|------|------|
| `__shfl_sync` | ì›Œí”„ ì…”í”Œ | âœ… |
| `__shfl_up_sync` | ì—… ì…”í”Œ | âœ… |
| `__shfl_down_sync` | ë‹¤ìš´ ì…”í”Œ | âœ… |
| `__shfl_xor_sync` | XOR ì…”í”Œ | âœ… |
| `__ballot_sync` | ì›Œí”„ íˆ¬í‘œ | âœ… |
| `__all_sync` | ì „ì²´ ì°¸ ê²€ì‚¬ | âœ… |
| `__any_sync` | ì¼ë¶€ ì°¸ ê²€ì‚¬ | âœ… |
| `__activemask()` | í™œì„± ìŠ¤ë ˆë“œ ë§ˆìŠ¤í¬ | âœ… |

### 4.8 ìŠ¤íŠ¸ë¦¼ ë° ì´ë²¤íŠ¸

| í•¨ìˆ˜ | ì„¤ëª… | ì§€ì› |
|------|------|------|
| `cudaStreamCreate` | ìŠ¤íŠ¸ë¦¼ ìƒì„± | âœ… |
| `cudaStreamDestroy` | ìŠ¤íŠ¸ë¦¼ ì œê±° | âœ… |
| `cudaStreamSynchronize` | ìŠ¤íŠ¸ë¦¼ ë™ê¸°í™” | âœ… |
| `cudaEventCreate` | ì´ë²¤íŠ¸ ìƒì„± | âœ… |
| `cudaEventRecord` | ì´ë²¤íŠ¸ ê¸°ë¡ | âœ… |
| `cudaEventSynchronize` | ì´ë²¤íŠ¸ ë™ê¸°í™” | âœ… |
| `cudaEventElapsedTime` | ê²½ê³¼ ì‹œê°„ (í•­ìƒ 0) | âš ï¸ |

### 4.9 í…ìŠ¤ì²˜ ë©”ëª¨ë¦¬

| í•¨ìˆ˜ | ì„¤ëª… | ì§€ì› |
|------|------|------|
| `tex1D` | 1D í…ìŠ¤ì²˜ ì½ê¸° | âœ… |
| `tex2D` | 2D í…ìŠ¤ì²˜ ì½ê¸° | âœ… |
| `tex1Dfetch` | 1D ì •ìˆ˜ ì¢Œí‘œ | âœ… |
| `tex2Dfetch` | 2D ì •ìˆ˜ ì¢Œí‘œ | âœ… |

### 4.10 ë°ì´í„° íƒ€ì…

| íƒ€ì… | ì§€ì› |
|------|------|
| `int`, `unsigned int` | âœ… |
| `float`, `double` | âœ… |
| `char`, `unsigned char` | âœ… |
| `short`, `unsigned short` | âœ… |
| `long`, `unsigned long` | âœ… |
| `long long`, `unsigned long long` | âœ… |
| `size_t` | âœ… |
| `bool` | âœ… |
| `void` | âœ… |
| `dim3` | âœ… |
| í¬ì¸í„° (`int*`, `float**`) | âœ… |
| ë°°ì—´ (`int arr[N]`) | âœ… |
| ë‹¤ì°¨ì› ë°°ì—´ | âœ… |
| `struct` | âœ… |
| `enum` | âœ… |
| `typedef` | âœ… |

### 4.11 ì—°ì‚°ì

| ì¹´í…Œê³ ë¦¬ | ì—°ì‚°ì | ì§€ì› |
|----------|--------|------|
| ì‚°ìˆ  | `+`, `-`, `*`, `/`, `%` | âœ… |
| ë¹„êµ | `==`, `!=`, `<`, `>`, `<=`, `>=` | âœ… |
| ë…¼ë¦¬ | `&&`, `\|\|`, `!` | âœ… |
| ë¹„íŠ¸ | `&`, `\|`, `^`, `~`, `<<`, `>>` | âœ… |
| ëŒ€ì… | `=`, `+=`, `-=`, `*=`, `/=`, `%=` | âœ… |
| ëŒ€ì… (ë¹„íŠ¸) | `&=`, `\|=`, `^=`, `<<=`, `>>=` | âœ… |
| ì¦ê° | `++`, `--` (ì „ìœ„/í›„ìœ„) | âœ… |
| ì‚¼í•­ | `? :` | âœ… |
| í¬ì¸í„° | `*`, `&`, `->` | âœ… |
| sizeof | `sizeof(type)`, `sizeof(expr)` | âœ… |
| ìºìŠ¤íŒ… | `(type)expr` | âœ… |

### 4.12 ì œì–´ êµ¬ì¡°

| êµ¬ì¡° | ì§€ì› |
|------|------|
| `if-else` | âœ… |
| `for` ë£¨í”„ | âœ… |
| `while` ë£¨í”„ | âœ… |
| `do-while` ë£¨í”„ | âœ… |
| `switch-case-default` | âœ… |
| `break` | âœ… |
| `continue` | âœ… |
| `return` | âœ… |

---

## 5. ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

### 5.1 í—ˆìš©ëœ í—¤ë” (stdio.h)

```c
// ì…ì¶œë ¥ í•¨ìˆ˜
printf()     // ì¶œë ¥
scanf()      // ì…ë ¥
fprintf()    // íŒŒì¼ ì¶œë ¥
fscanf()     // íŒŒì¼ ì…ë ¥
fopen()      // íŒŒì¼ ì—´ê¸°
fclose()     // íŒŒì¼ ë‹«ê¸°
fread()      // ë°”ì´ë„ˆë¦¬ ì½ê¸°
fwrite()     // ë°”ì´ë„ˆë¦¬ ì“°ê¸°
fgets()      // ë¼ì¸ ì½ê¸°
fputs()      // ë¼ì¸ ì“°ê¸°
getchar()    // ë¬¸ì ì…ë ¥
putchar()    // ë¬¸ì ì¶œë ¥
```

### 5.2 í—ˆìš©ëœ í•¨ìˆ˜ (stdlib.h ì¼ë¶€)

```c
// ë©”ëª¨ë¦¬ ê´€ë¦¬
malloc()     // ë©”ëª¨ë¦¬ í• ë‹¹
calloc()     // 0 ì´ˆê¸°í™” ë©”ëª¨ë¦¬ í• ë‹¹
realloc()    // ë©”ëª¨ë¦¬ ì¬í• ë‹¹
free()       // ë©”ëª¨ë¦¬ í•´ì œ

// ë³€í™˜ í•¨ìˆ˜
atoi()       // ë¬¸ìì—´ â†’ ì •ìˆ˜
atof()       // ë¬¸ìì—´ â†’ ì‹¤ìˆ˜
atol()       // ë¬¸ìì—´ â†’ long
strtol()     // ë¬¸ìì—´ â†’ long (ì§„ë²• ì§€ì •)
strtod()     // ë¬¸ìì—´ â†’ double

// ë‚œìˆ˜
rand()       // ë‚œìˆ˜ ìƒì„±
srand()      // ì‹œë“œ ì„¤ì •

// ê¸°íƒ€
abs()        // ì ˆëŒ“ê°’
exit()       // í”„ë¡œê·¸ë¨ ì¢…ë£Œ
```

### 5.3 í—ˆìš©ëœ ìˆ˜í•™ í•¨ìˆ˜ (math.h)

```c
// ê¸°ë³¸ ìˆ˜í•™ í•¨ìˆ˜
sin(), cos(), tan()      // ì‚¼ê°í•¨ìˆ˜
asin(), acos(), atan()   // ì—­ì‚¼ê°í•¨ìˆ˜
sinh(), cosh(), tanh()   // ìŒê³¡ì„ í•¨ìˆ˜
exp(), log(), log10()    // ì§€ìˆ˜/ë¡œê·¸
pow(), sqrt()            // ê±°ë“­ì œê³±/ì œê³±ê·¼
ceil(), floor(), round() // ì˜¬ë¦¼/ë‚´ë¦¼/ë°˜ì˜¬ë¦¼
fabs(), fmod()           // ì ˆëŒ“ê°’/ë‚˜ë¨¸ì§€
fmin(), fmax()           // ìµœì†Ÿê°’/ìµœëŒ“ê°’
```

### 5.4 í—ˆìš©ëœ í•¨ìˆ˜ (string.h / cstring)

```c
// ë¬¸ìì—´ ë³µì‚¬/ì—°ê²°
strcpy()     // ë¬¸ìì—´ ë³µì‚¬
strncpy()    // ë¬¸ìì—´ ë³µì‚¬ (nê°œ ë¬¸ì)
strcat()     // ë¬¸ìì—´ ì—°ê²°
strncat()    // ë¬¸ìì—´ ì—°ê²° (nê°œ ë¬¸ì)

// ë¬¸ìì—´ ë¹„êµ
strcmp()     // ë¬¸ìì—´ ë¹„êµ
strncmp()    // ë¬¸ìì—´ ë¹„êµ (nê°œ ë¬¸ì)

// ë¬¸ìì—´ ê²€ìƒ‰
strlen()     // ë¬¸ìì—´ ê¸¸ì´
strchr()     // ë¬¸ì ì°¾ê¸° (ì²˜ìŒ)
strrchr()    // ë¬¸ì ì°¾ê¸° (ë§ˆì§€ë§‰)
strstr()     // ë¶€ë¶„ ë¬¸ìì—´ ì°¾ê¸°
strpbrk()    // ë¬¸ì ì§‘í•©ì—ì„œ ì°¾ê¸°
strspn()     // ë¬¸ì ì§‘í•© ë‚´ ì—°ì† ê¸¸ì´
strcspn()    // ë¬¸ì ì§‘í•© ì™¸ ì—°ì† ê¸¸ì´
strtok()     // í† í° ë¶„ë¦¬

// ë©”ëª¨ë¦¬ ì¡°ì‘
memcpy()     // ë©”ëª¨ë¦¬ ë³µì‚¬
memmove()    // ë©”ëª¨ë¦¬ ì´ë™ (ì¤‘ì²© ì•ˆì „)
memcmp()     // ë©”ëª¨ë¦¬ ë¹„êµ
memset()     // ë©”ëª¨ë¦¬ ì„¤ì •
memchr()     // ë©”ëª¨ë¦¬ì—ì„œ ë°”ì´íŠ¸ ì°¾ê¸°
```

---

## 6. ì‚¬ìš© ê¸ˆì§€ í•­ëª©

### 6.1 ê¸ˆì§€ëœ í•¨ìˆ˜ ëª©ë¡

> âš ï¸ ë‹¤ìŒ í•¨ìˆ˜ë“¤ì€ **ì§ì ‘ êµ¬í˜„**í•´ì•¼ í•©ë‹ˆë‹¤.

#### stdlib.h ê¸ˆì§€ í•¨ìˆ˜
```c
qsort()      // âŒ ì •ë ¬ ì§ì ‘ êµ¬í˜„ í•„ìš”
bsearch()    // âŒ ì´ì§„ íƒìƒ‰ ì§ì ‘ êµ¬í˜„ í•„ìš”
```

#### STL algorithm í•¨ìˆ˜
```c
// ì •ë ¬
sort(), stable_sort(), partial_sort(), nth_element()

// ê²€ìƒ‰
find(), find_if(), find_first_of(), binary_search()
lower_bound(), upper_bound(), equal_range()

// ìˆ˜ì •
copy(), fill(), transform(), replace(), swap()
reverse(), rotate(), shuffle(), unique(), remove()

// ì§‘ê³„
count(), count_if(), accumulate(), inner_product()
min(), max(), min_element(), max_element()

// ë°˜ë³µ
for_each(), all_of(), any_of(), none_of()
```

#### STL ì»¨í…Œì´ë„ˆ ë©”ì„œë“œ
```c
push_back(), pop_back(), push_front(), pop_front()
emplace(), insert(), erase(), clear(), resize()
begin(), end(), front(), back(), at(), size()
```

### 6.2 ê¸ˆì§€ëœ íƒ€ì… ëª©ë¡

> âš ï¸ C++ STL ì»¨í…Œì´ë„ˆëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. **C ìŠ¤íƒ€ì¼ ë°°ì—´ê³¼ í¬ì¸í„°**ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

```cpp
// âŒ ê¸ˆì§€ëœ STL ì»¨í…Œì´ë„ˆ
std::vector<T>         // â†’ int arr[N] ë˜ëŠ” int* arr ì‚¬ìš©
std::string            // â†’ char arr[N] ë˜ëŠ” char* ì‚¬ìš©
std::map<K,V>          // â†’ ì§ì ‘ êµ¬í˜„ í•„ìš”
std::unordered_map<K,V>
std::set<T>
std::unordered_set<T>
std::list<T>
std::deque<T>
std::queue<T>
std::stack<T>
std::priority_queue<T>
std::pair<T,U>
std::tuple<...>
std::array<T,N>
std::bitset<N>

// âŒ ê¸ˆì§€ëœ ë™ê¸°í™” íƒ€ì…
std::mutex
std::thread
std::atomic<T>

// âŒ ê¸ˆì§€ëœ ìŠ¤ë§ˆíŠ¸ í¬ì¸í„°
std::shared_ptr<T>
std::unique_ptr<T>
std::weak_ptr<T>
```

### 6.3 ì˜¬ë°”ë¥¸ ëŒ€ì•ˆ

```cuda
// âŒ í‹€ë¦° ì˜ˆ (vector ì‚¬ìš©)
std::vector<int> arr(N);

// âœ… ì˜¬ë°”ë¥¸ ì˜ˆ (C ìŠ¤íƒ€ì¼ ë°°ì—´)
int arr[N];           // ê³ ì • í¬ê¸°
int* arr = (int*)malloc(N * sizeof(int));  // ë™ì  í• ë‹¹

// âŒ í‹€ë¦° ì˜ˆ (string ì‚¬ìš©)
std::string str = "hello";

// âœ… ì˜¬ë°”ë¥¸ ì˜ˆ (C ìŠ¤íƒ€ì¼ ë¬¸ìì—´)
char str[] = "hello";
char* str = "hello";

// âŒ í‹€ë¦° ì˜ˆ (sort ì‚¬ìš©)
std::sort(arr, arr + n);

// âœ… ì˜¬ë°”ë¥¸ ì˜ˆ (ì§ì ‘ êµ¬í˜„)
__device__ void bubbleSort(int* arr, int n) {
    for (int i = 0; i < n - 1; i++) {
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                int temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
            }
        }
    }
}
```

---

## 7. ì—ëŸ¬ ì½”ë“œ ëª©ë¡

### 7.1 E1xxx: ë¬¸ë²• ì—ëŸ¬ (SYNTAX_ERROR)

> ì‚¬ìš©ìê°€ ìˆ˜ì •í•´ì•¼ í•˜ëŠ” CUDA C ë¬¸ë²• ì˜¤ë¥˜

| ì½”ë“œ | ì´ë¦„ | ì„¤ëª… | í•´ê²° ë°©ë²• |
|------|------|------|-----------|
| E1001 | UNEXPECTED_TOKEN | ì˜ˆìƒì¹˜ ëª»í•œ í† í° | ë¬¸ë²• í™•ì¸ |
| E1002 | MISSING_SEMICOLON | ì„¸ë¯¸ì½œë¡  ëˆ„ë½ | `;` ì¶”ê°€ |
| E1003 | UNMATCHED_BRACKET | ê´„í˜¸ ë¶ˆì¼ì¹˜ | `{}`, `()`, `[]` ìŒ í™•ì¸ |
| E1004 | INVALID_EXPRESSION | ì˜ëª»ëœ í‘œí˜„ì‹ | í‘œí˜„ì‹ ë¬¸ë²• í™•ì¸ |
| E1005 | MISSING_TYPE | íƒ€ì… ëˆ„ë½ | ë³€ìˆ˜/í•¨ìˆ˜ íƒ€ì… ëª…ì‹œ |
| E1006 | INVALID_DECLARATION | ì˜ëª»ëœ ì„ ì–¸ | ì„ ì–¸ë¬¸ í™•ì¸ |
| E1007 | EXPECTED_IDENTIFIER | ì‹ë³„ì í•„ìš” | ë³€ìˆ˜/í•¨ìˆ˜ëª… í™•ì¸ |
| E1008 | INVALID_KERNEL_LAUNCH | ì˜ëª»ëœ ì»¤ë„ ëŸ°ì¹˜ | `<<<>>>` êµ¬ë¬¸ í™•ì¸ |
| E1009 | INVALID_ARRAY_SIZE | ì˜ëª»ëœ ë°°ì—´ í¬ê¸° | ë°°ì—´ í¬ê¸° í™•ì¸ |
| E1010 | INVALID_OPERATOR | ì˜ëª»ëœ ì—°ì‚°ì | ì—°ì‚°ì í™•ì¸ |

### 7.2 E2xxx: ì˜ë¯¸ë¡  ì—ëŸ¬ (SEMANTIC_ERROR)

> CUDA ì˜ë¯¸ë¡  ê·œì¹™ ìœ„ë°˜

| ì½”ë“œ | ì´ë¦„ | ì„¤ëª… | í•´ê²° ë°©ë²• |
|------|------|------|-----------|
| E2001 | INVALID_MEMCPY_DIRECTION | cudaMemcpy ë°©í–¥ ì˜¤ë¥˜ | Host/Device í¬ì¸í„° í™•ì¸ |
| E2002 | DEVICE_VAR_IN_HOST | í˜¸ìŠ¤íŠ¸ì—ì„œ __device__ ì ‘ê·¼ | cudaMemcpyToSymbol ì‚¬ìš© |
| E2003 | HOST_VAR_IN_DEVICE | ì»¤ë„ì—ì„œ í˜¸ìŠ¤íŠ¸ ë³€ìˆ˜ ì ‘ê·¼ | íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ |
| E2004 | SHARED_MEMORY_IN_HOST | í˜¸ìŠ¤íŠ¸ì—ì„œ __shared__ ì‚¬ìš© | ì»¤ë„ ë‚´ë¶€ì—ì„œë§Œ ì‚¬ìš© |
| E2005 | CONSTANT_WRITE_IN_KERNEL | ì»¤ë„ì—ì„œ __constant__ ì“°ê¸° | __constant__ëŠ” ì½ê¸° ì „ìš© |
| E2006 | INVALID_MEMORY_ACCESS | ì˜ëª»ëœ ë©”ëª¨ë¦¬ ì ‘ê·¼ | í¬ì¸í„° í™•ì¸ |
| E2007 | HOST_FUNC_IN_KERNEL | ì»¤ë„ì—ì„œ í˜¸ìŠ¤íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ | __device__ í•¨ìˆ˜ ì‚¬ìš© |
| E2008 | HOST_VAR_ACCESS_IN_KERNEL | ì»¤ë„ì—ì„œ í˜¸ìŠ¤íŠ¸ ë³€ìˆ˜ ì ‘ê·¼ | __device__ ë˜ëŠ” íŒŒë¼ë¯¸í„° ì‚¬ìš© |
| E2009 | DEVICE_FUNC_IN_HOST | í˜¸ìŠ¤íŠ¸ì—ì„œ __device__ í•¨ìˆ˜ í˜¸ì¶œ | __host__ __device__ ì¶”ê°€ |
| E2010 | GLOBAL_FUNC_IN_KERNEL | ì»¤ë„ ë‚´ ì»¤ë„ í˜¸ì¶œ ì‹œë„ | ë™ì  ë³‘ë ¬í™” ë¯¸ì§€ì› |

### 7.3 E3xxx: ê²€ì¦ ì—ëŸ¬ (VALIDATION_ERROR)

> OJ ì •ì±… ìœ„ë°˜ - êµìœ¡ ëª©ì ìƒì˜ ì œí•œ

| ì½”ë“œ | ì´ë¦„ | ì„¤ëª… | í•´ê²° ë°©ë²• |
|------|------|------|-----------|
| E3001 | NO_KERNEL_FOUND | ì»¤ë„ í•¨ìˆ˜ ì—†ìŒ/ë¯¸í˜¸ì¶œ | `__global__` í•¨ìˆ˜ ì‘ì„± ë° í˜¸ì¶œ |
| E3002 | KERNEL_NOT_SIGNIFICANT | ì»¤ë„ì´ ì˜ë¯¸ì—†ìŒ | ì‹¤ì œ ì—°ì‚° ìˆ˜í–‰í•˜ëŠ” ì½”ë“œ ì¶”ê°€ |
| E3003 | NO_PARALLELISM | ë³‘ë ¬ì²˜ë¦¬ ë¯¸ì‚¬ìš© | `threadIdx`, `blockIdx` ì‚¬ìš© |
| E3004 | NO_GPU_MEMORY_OPS | GPU ë©”ëª¨ë¦¬ ë¯¸ì‚¬ìš© | `cudaMalloc`, `cudaMemcpy` ì‚¬ìš© |
| E3005 | FORBIDDEN_FUNCTION | ê¸ˆì§€ í•¨ìˆ˜ ì‚¬ìš© | [ê¸ˆì§€ í•¨ìˆ˜ ëª©ë¡](#61-ê¸ˆì§€ëœ-í•¨ìˆ˜-ëª©ë¡) ì°¸ì¡° |
| E3006 | FORBIDDEN_TYPE | ê¸ˆì§€ íƒ€ì… ì‚¬ìš© | [ê¸ˆì§€ íƒ€ì… ëª©ë¡](#62-ê¸ˆì§€ëœ-íƒ€ì…-ëª©ë¡) ì°¸ì¡° |

### 7.4 E4xxx: ë¯¸ì§€ì› ê¸°ëŠ¥ (NOT_SUPPORTED)

> íŠ¸ëœìŠ¤íŒŒì¼ëŸ¬ê°€ ì§€ì›í•˜ì§€ ì•ŠëŠ” CUDA ê¸°ëŠ¥

| ì½”ë“œ | ì´ë¦„ | ì„¤ëª… | ëŒ€ì•ˆ |
|------|------|------|------|
| E4001 | UNSUPPORTED_FEATURE | ì¼ë°˜ ë¯¸ì§€ì› ê¸°ëŠ¥ | ë¬¸ì„œ ì°¸ì¡° |
| E4002 | COMPLEX_TEMPLATE | ë³µì¡í•œ í…œí”Œë¦¿ | ë‹¨ìˆœí™” í•„ìš” |
| E4003 | INLINE_PTX | ì¸ë¼ì¸ PTX ì–´ì…ˆë¸”ë¦¬ | C++ ì½”ë“œë¡œ ëŒ€ì²´ |
| E4005 | DYNAMIC_PARALLELISM | ë™ì  ë³‘ë ¬ì²˜ë¦¬ | í˜¸ìŠ¤íŠ¸ì—ì„œ ì»¤ë„ í˜¸ì¶œ |
| E4006 | COOPERATIVE_GROUPS | í˜‘ë ¥ ê·¸ë£¹ | __syncthreads ì‚¬ìš© |
| E4008 | UNIFIED_MEMORY | í†µí•© ë©”ëª¨ë¦¬ | cudaMalloc + cudaMemcpy |

### 7.5 E5xxx: ë‚´ë¶€ ì—ëŸ¬ (INTERNAL_ERROR)

> ì‹œìŠ¤í…œ ë‚´ë¶€ ì˜¤ë¥˜ (ì‚¬ìš©ì ì±…ì„ ì•„ë‹˜)

| ì½”ë“œ | ì´ë¦„ | ì„¤ëª… |
|------|------|------|
| E5001 | PARSER_INTERNAL | íŒŒì„œ ë‚´ë¶€ ì˜¤ë¥˜ |
| E5002 | TRANSPILER_INTERNAL | íŠ¸ëœìŠ¤íŒŒì¼ëŸ¬ ë‚´ë¶€ ì˜¤ë¥˜ |
| E5003 | CODE_GEN_FAILED | ì½”ë“œ ìƒì„± ì‹¤íŒ¨ |
| E5999 | UNKNOWN_INTERNAL | ì•Œ ìˆ˜ ì—†ëŠ” ë‚´ë¶€ ì˜¤ë¥˜ |

---

## 8. ì½”ë”© ê°€ì´ë“œë¼ì¸

### 8.1 ê¸°ë³¸ í…œí”Œë¦¿

```cuda
#include <stdio.h>

// ì»¤ë„ í•¨ìˆ˜ ì •ì˜
__global__ void myKernel(int* input, int* output, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx < n) {
        // ì‹¤ì œ ì—°ì‚° ìˆ˜í–‰
        output[idx] = input[idx] * 2;
    }
}

int main() {
    int n;
    scanf("%d", &n);
    
    // í˜¸ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ í• ë‹¹
    int* h_input = (int*)malloc(n * sizeof(int));
    int* h_output = (int*)malloc(n * sizeof(int));
    
    // ì…ë ¥ ì½ê¸°
    for (int i = 0; i < n; i++) {
        scanf("%d", &h_input[i]);
    }
    
    // ë””ë°”ì´ìŠ¤ ë©”ëª¨ë¦¬ í• ë‹¹
    int *d_input, *d_output;
    cudaMalloc(&d_input, n * sizeof(int));
    cudaMalloc(&d_output, n * sizeof(int));
    
    // í˜¸ìŠ¤íŠ¸ â†’ ë””ë°”ì´ìŠ¤ ë³µì‚¬
    cudaMemcpy(d_input, h_input, n * sizeof(int), cudaMemcpyHostToDevice);
    
    // ì»¤ë„ ì‹¤í–‰
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    myKernel<<<gridSize, blockSize>>>(d_input, d_output, n);
    
    // ë””ë°”ì´ìŠ¤ â†’ í˜¸ìŠ¤íŠ¸ ë³µì‚¬
    cudaMemcpy(h_output, d_output, n * sizeof(int), cudaMemcpyDeviceToHost);
    
    // ê²°ê³¼ ì¶œë ¥
    for (int i = 0; i < n; i++) {
        printf("%d ", h_output[i]);
    }
    printf("\n");
    
    // ë©”ëª¨ë¦¬ í•´ì œ
    cudaFree(d_input);
    cudaFree(d_output);
    free(h_input);
    free(h_output);
    
    return 0;
}
```

### 8.2 Atomic ì—°ì‚° ì˜ˆì œ

```cuda
#include <stdio.h>

__global__ void sumKernel(int* arr, int n, int* result) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx < n) {
        atomicAdd(result, arr[idx]);  // ì›ìì  ë§ì…ˆ
    }
}

int main() {
    int n = 1000;
    int* h_arr = (int*)malloc(n * sizeof(int));
    for (int i = 0; i < n; i++) h_arr[i] = 1;
    
    int *d_arr, *d_result;
    int h_result = 0;
    
    cudaMalloc(&d_arr, n * sizeof(int));
    cudaMalloc(&d_result, sizeof(int));
    
    cudaMemcpy(d_arr, h_arr, n * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_result, &h_result, sizeof(int), cudaMemcpyHostToDevice);
    
    sumKernel<<<10, 100>>>(d_arr, n, d_result);
    
    cudaMemcpy(&h_result, d_result, sizeof(int), cudaMemcpyDeviceToHost);
    printf("Sum: %d\n", h_result);  // 1000
    
    cudaFree(d_arr);
    cudaFree(d_result);
    free(h_arr);
    
    return 0;
}
```

### 8.3 Shared Memory ì˜ˆì œ

```cuda
#include <stdio.h>

#define BLOCK_SIZE 256

__global__ void sharedMemSum(int* input, int* output, int n) {
    __shared__ int shared_data[BLOCK_SIZE];
    
    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    // ê³µìœ  ë©”ëª¨ë¦¬ì— ë¡œë“œ
    shared_data[tid] = (idx < n) ? input[idx] : 0;
    __syncthreads();
    
    // ë¦¬ë•ì…˜
    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {
        if (tid < stride) {
            shared_data[tid] += shared_data[tid + stride];
        }
        __syncthreads();
    }
    
    // ë¸”ë¡ ê²°ê³¼ ì €ì¥
    if (tid == 0) {
        output[blockIdx.x] = shared_data[0];
    }
}
```

### 8.4 2D ê·¸ë¦¬ë“œ/ë¸”ë¡ ì˜ˆì œ

```cuda
#include <stdio.h>

#define N 16
#define BLOCK_SIZE 4

__global__ void matrixAdd(int* A, int* B, int* C, int width) {
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (row < width && col < width) {
        int idx = row * width + col;
        C[idx] = A[idx] + B[idx];
    }
}

int main() {
    int size = N * N * sizeof(int);
    
    int *h_A, *h_B, *h_C;
    int *d_A, *d_B, *d_C;
    
    h_A = (int*)malloc(size);
    h_B = (int*)malloc(size);
    h_C = (int*)malloc(size);
    
    // ì´ˆê¸°í™”
    for (int i = 0; i < N * N; i++) {
        h_A[i] = i;
        h_B[i] = i * 2;
    }
    
    cudaMalloc(&d_A, size);
    cudaMalloc(&d_B, size);
    cudaMalloc(&d_C, size);
    
    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);
    
    // 2D ê·¸ë¦¬ë“œ ì„¤ì •
    dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);
    dim3 gridDim((N + BLOCK_SIZE - 1) / BLOCK_SIZE, 
                 (N + BLOCK_SIZE - 1) / BLOCK_SIZE);
    
    matrixAdd<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);
    
    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);
    
    // ê²°ê³¼ ì¶œë ¥ (ì²« ë²ˆì§¸ í–‰ë§Œ)
    for (int i = 0; i < N; i++) {
        printf("%d ", h_C[i]);
    }
    printf("\n");
    
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
    free(h_A);
    free(h_B);
    free(h_C);
    
    return 0;
}
```

---

## 9. ì£¼ì˜ì‚¬í•­ ë° ì œí•œì‚¬í•­

### 9.1 ë™ì‘ ì°¨ì´

| í•­ëª© | GPU ë™ì‘ | CPU ì—ë®¬ë ˆì´ì…˜ |
|------|----------|----------------|
| ë³‘ë ¬ ì‹¤í–‰ | ë™ì‹œ ì‹¤í–‰ | ìˆœì°¨ ì‹œë®¬ë ˆì´ì…˜ |
| `cudaEvent` ì‹œê°„ | ì‹¤ì œ ì¸¡ì • | í•­ìƒ 0 |
| ë©”ëª¨ë¦¬ ëŒ€ì—­í­ | ê³ ì† | ì‹œìŠ¤í…œ RAM ì†ë„ |
| Warp ë™ê¸°í™” | í•˜ë“œì›¨ì–´ ì§€ì› | ì†Œí”„íŠ¸ì›¨ì–´ ì—ë®¬ë ˆì´ì…˜ |
| ìŠ¤íŠ¸ë¦¼ | ë¹„ë™ê¸° ì‹¤í–‰ | ë™ê¸° ì‹¤í–‰ |

### 9.2 Best Practices

1. **ê²½ê³„ ê²€ì‚¬ í•­ìƒ ìˆ˜í–‰**
   ```cuda
   if (idx < n) {
       // ì•ˆì „í•œ ì ‘ê·¼
   }
   ```

2. **ë©”ëª¨ë¦¬ í•´ì œ ìŠì§€ ì•Šê¸°**
   ```cuda
   cudaFree(d_ptr);
   free(h_ptr);
   ```

3. **ì ì ˆí•œ ë¸”ë¡ í¬ê¸° ì‚¬ìš©**
   ```cuda
   // ì¼ë°˜ì ìœ¼ë¡œ 128 ~ 512 ê¶Œì¥
   int blockSize = 256;
   ```

4. **Shared Memory í¬ê¸° ì œí•œ ê³ ë ¤**
   ```cuda
   // ë¸”ë¡ë‹¹ 48KB ì œí•œ (ì‹¤ì œ GPU)
   __shared__ float data[1024];  // 4KB
   ```

5. **Race Condition ë°©ì§€**
   ```cuda
   atomicAdd(&sum, value);  // ë™ì‹œ ì“°ê¸° ì‹œ atomic ì‚¬ìš©
   ```

---

## 10. ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)

### Q1: ì™œ `std::vector`ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ë‚˜ìš”?

**A:** êµìœ¡ ëª©ì ìƒ, C ìŠ¤íƒ€ì¼ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í•™ìŠµí•˜ë„ë¡ ì˜ë„ë˜ì—ˆìŠµë‹ˆë‹¤. 
ì‹¤ì œ CUDA ê°œë°œì—ì„œë„ GPU ë©”ëª¨ë¦¬ëŠ” C ìŠ¤íƒ€ì¼ í¬ì¸í„°ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

```cuda
// âŒ ê¸ˆì§€
std::vector<int> arr(N);

// âœ… ê¶Œì¥
int* arr = (int*)malloc(N * sizeof(int));
```

### Q2: ì‹¤í–‰ ì‹œê°„ì´ ëŠë¦° ê²ƒ ê°™ì€ë°, ì½”ë“œê°€ ë¹„íš¨ìœ¨ì ì¸ ê±´ê°€ìš”?

**A:** ì•„ë‹™ë‹ˆë‹¤. CPU íŠ¸ëœìŠ¤íŒŒì¼ëŸ¬ëŠ” **ì •í™•ì„± ê²€ì¦ìš©**ì´ë¯€ë¡œ ì‹¤ì œ GPU ì„±ëŠ¥ê³¼ ë‹¤ë¦…ë‹ˆë‹¤.
ì‹¤ì œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ëŠ” GPU í™˜ê²½ì—ì„œ í•´ì•¼ í•©ë‹ˆë‹¤.

### Q3: `cudaEventElapsedTime`ì´ í•­ìƒ 0ì„ ë°˜í™˜í•´ìš”.

**A:** ì •ìƒì…ë‹ˆë‹¤. CPU ì—ë®¬ë ˆì´ì…˜ì—ì„œëŠ” ëª¨ë“  ì—°ì‚°ì´ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ 
ê²½ê³¼ ì‹œê°„ ì¸¡ì •ì´ ì˜ë¯¸ê°€ ì—†ìŠµë‹ˆë‹¤.

### Q4: E3003 (NO_PARALLELISM) ì—ëŸ¬ê°€ ë°œìƒí•´ìš”.

**A:** ì»¤ë„ ë‚´ì—ì„œ `threadIdx`, `blockIdx` ë“± ë³‘ë ¬ì²˜ë¦¬ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

```cuda
// âŒ ì—ëŸ¬ ë°œìƒ
__global__ void kernel(int* arr) {
    arr[0] = 1;  // ëª¨ë“  ìŠ¤ë ˆë“œê°€ ê°™ì€ ì‘ì—…
}

// âœ… í•´ê²°
__global__ void kernel(int* arr) {
    int i = threadIdx.x;  // ìŠ¤ë ˆë“œë³„ ë‹¤ë¥¸ ì¸ë±ìŠ¤
    arr[i] = i;
}
```

### Q5: ë™ì  ê³µìœ  ë©”ëª¨ë¦¬ëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?

**A:** `extern __shared__`ì™€ ì»¤ë„ ëŸ°ì¹˜ ì‹œ ì„¸ ë²ˆì§¸ ì¸ìë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```cuda
extern __shared__ int shared[];

__global__ void kernel(int* data, int n) {
    int tid = threadIdx.x;
    shared[tid] = data[tid];
    __syncthreads();
    // ...
}

int main() {
    // ì„¸ ë²ˆì§¸ ì¸ì: ë™ì  shared memory í¬ê¸° (ë°”ì´íŠ¸)
    kernel<<<1, 256, 256 * sizeof(int)>>>(d_data, n);
}
```

### Q6: ì™œ cudaMemcpy ë°©í–¥ ê²€ì¦ ì—ëŸ¬(E2001)ê°€ ë°œìƒí•˜ë‚˜ìš”?

**A:** `cudaMalloc`ìœ¼ë¡œ í• ë‹¹í•œ í¬ì¸í„°ì™€ í˜¸ìŠ¤íŠ¸ í¬ì¸í„°ì˜ ë°©í–¥ì´ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.

```cuda
// âŒ ì—ëŸ¬: d_arrì€ Deviceì¸ë° srcë¡œ ì‚¬ìš©
cudaMemcpy(h_arr, d_arr, size, cudaMemcpyHostToDevice);

// âœ… ì˜¬ë°”ë¦„: d_arrì€ src, DeviceToHost
cudaMemcpy(h_arr, d_arr, size, cudaMemcpyDeviceToHost);
```

---

## ğŸ“ ë„ì›€ë§ ë° ì§€ì›

- **ë¬¸ì˜**: ğŸ“§ [ejpark29@gmail.com](mailto:ejpark29@gmail.com)

---

**ë²„ì „**: 2.1.0  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025ë…„ 12ì›”

---

**Happy CUDA Learning! ğŸš€**
