# Print Hello World Cuda

| Difficulty | Memory Limit | Time Limit | Author |
|------------|--------------|------------|--------|
| Easy | 128 MB | 1 s | MenOfPassion |

## Problem Description

This is a simple output-only problem.

Your task is to write a CUDA program that prints the exact phrase **"Hello World Cuda"**.

### Input
There is no input.

### Output
Print the following text exactly:
```
Hello World Cuda
```

---

## Solution Code

> **Note**: CUDA Online Judge automatically removes all user-written `#include` statements and includes only the allowed libraries. You don't need to write any `#include` in your code.

```cuda
__global__ void helloKernel(int* dummy) {
    if (threadIdx.x == 0) {
        printf("Hello World Cuda\n");
    }
}

int main() {
    // Allocate GPU memory (required for validation)
    int* d_dummy;
    cudaMalloc(&d_dummy, sizeof(int));
    
    // Launch kernel
    helloKernel<<<1, 1>>>(d_dummy);
    
    // Wait for kernel to complete
    cudaDeviceSynchronize();
    
    // Free GPU memory
    cudaFree(d_dummy);
    
    return 0;
}
```

> ğŸ“š New to CUDA OJ? Read the [CUDA Online Judge Guide](../../GUIDE.md) first.

### Why This Code Structure?

CUDA Online Judge requires code to pass validation checks:

| Requirement | How We Satisfy It |
|-------------|-------------------|
| âœ… Kernel exists | `__global__ void helloKernel()` |
| âœ… Uses parallelism | `threadIdx.x` in condition |
| âœ… Uses GPU memory | `cudaMalloc` / `cudaFree` |
| âœ… Kernel called | `<<<1, 1>>>` launch syntax |
| âœ… Meaningful computation | `printf()` output |

---

## CUDA Concepts Covered

### 1. Basic CUDA Program Structure

A CUDA program consists of two main parts:
- **Host code**: Runs on the CPU
- **Device code**: Runs on the GPU

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CUDA Program               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Host (CPU)    â”‚    Device (GPU)       â”‚
â”‚                 â”‚                       â”‚
â”‚  - main()       â”‚  - __global__ kernels â”‚
â”‚  - Memory mgmt  â”‚  - __device__ funcs   â”‚
â”‚  - Kernel launchâ”‚  - Parallel execution â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. The `__global__` Keyword

The `__global__` keyword declares a **kernel function** that:
- Is called from the **host** (CPU)
- Executes on the **device** (GPU)
- Must return `void`

```cuda
__global__ void kernelName() {
    // This code runs on GPU
}
```

### 3. Kernel Launch Syntax: `<<<blocks, threads>>>`

```cuda
helloKernel<<<1, 1>>>(d_dummy);
//           â”‚  â”‚
//           â”‚  â””â”€â”€ Threads per block
//           â””â”€â”€â”€â”€â”€ Number of blocks
```

In this problem, we launch with `<<<1, 1>>>`:
- **1 block** containing **1 thread**
- Only one thread executes the kernel

### 4. Built-in Variables for Parallelism

CUDA provides built-in variables to identify each thread:

| Variable | Description |
|----------|-------------|
| `threadIdx.x/y/z` | Thread index within block |
| `blockIdx.x/y/z` | Block index within grid |
| `blockDim.x/y/z` | Threads per block |
| `gridDim.x/y/z` | Blocks in grid |

```cuda
// Only thread 0 executes the print
if (threadIdx.x == 0) {
    printf("Hello World Cuda\n");
}
```

### 5. GPU Memory Management

CUDA requires explicit memory management:

| Function | Description |
|----------|-------------|
| `cudaMalloc` | Allocate GPU memory |
| `cudaMemcpy` | Copy data between host and device |
| `cudaFree` | Free GPU memory |

```cuda
int* d_ptr;
cudaMalloc(&d_ptr, sizeof(int));  // Allocate on GPU
cudaFree(d_ptr);                   // Free GPU memory
```

### 6. `cudaDeviceSynchronize()`

This function blocks the host (CPU) until all previously issued CUDA operations complete.

**Why is it needed?**
- Kernel launches are **asynchronous**
- Without synchronization, `main()` might exit before the kernel finishes
- `printf` from device needs synchronization to flush output

```
Timeline without cudaDeviceSynchronize():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
CPU: main() starts â†’ launch kernel â†’ main() exits
GPU:                  â†“ kernel starts... (may not complete!)

Timeline with cudaDeviceSynchronize():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
CPU: main() starts â†’ launch kernel â†’ wait... â†’ main() exits
GPU:                  â†“ kernel executes â†’ done â†‘
```

### 7. Device-side `printf`

CUDA supports `printf` inside device code (compute capability 2.0+).

Key points:
- `stdio.h` is automatically included by CUDA OJ
- Output is buffered and flushed on synchronization
- Useful for debugging but can impact performance

---

## Common Mistakes

### âŒ Missing Synchronization
```cuda
int main() {
    helloKernel<<<1, 1>>>(d_dummy);
    return 0;  // Program may exit before output appears!
}
```

### âŒ Missing GPU Memory Usage
```cuda
// Validation Error E3004: No GPU memory used
int main() {
    helloKernel<<<1, 1>>>();  // No cudaMalloc!
    cudaDeviceSynchronize();
    return 0;
}
```

### âŒ Missing Parallelism Variable
```cuda
// Validation Error E3003: No parallelism used
__global__ void helloKernel() {
    printf("Hello World Cuda\n");  // No threadIdx/blockIdx!
}
```

### âŒ Wrong Output Text
```cuda
printf("Hello World CUDA\n");  // "CUDA" vs "Cuda" - case matters!
```

---

## Key Takeaways

1. **CUDA OJ requires proper CUDA patterns** - even simple problems need kernel, parallelism, and GPU memory
2. **`__global__` functions** are the bridge between CPU and GPU
3. **Kernel launch syntax** `<<<blocks, threads>>>` controls parallelism
4. **Always synchronize** when device output is expected
5. **Exact output matching** is crucial in competitive programming

---

## Practice Exercises

1. Modify the kernel to launch with `<<<1, 5>>>` and observe what happens without the `if` condition
2. Try launching with `<<<5, 1>>>` and use `blockIdx.x` instead of `threadIdx.x`
3. Remove `cudaDeviceSynchronize()` and see if the output still appears

---

*This problem is from [CUDA Online Judge](https://cudaforces.com/problem/1)*
